# ==============================================
# LLM PROVIDER CONFIGURATION
# ==============================================
# Options: perplexity (1st choice), cerebras (2nd choice), ollama (3rd choice/local backup)
LLM_PROVIDER=perplexity

# ==============================================
# PERPLEXITY API CONFIGURATION (1ST CHOICE - RECOMMENDED)
# ==============================================
# Get your API key from: https://www.perplexity.ai/settings/api
# Fast inference, powerful models, real-time web search capabilities
PERPLEXITY_API_KEY=your_perplexity_api_key_here

# ==============================================
# CEREBRAS API CONFIGURATION (2ND CHOICE - FREE TIER)
# ==============================================
# Get your free API key from: https://cloud.cerebras.ai/
# Fast inference, no GPU required, fully compatible with CrewAI
CEREBRAS_API_KEY=your_cerebras_api_key_here

# ==============================================
# OLLAMA CONFIGURATION (3RD CHOICE - LOCAL BACKUP)
# ==============================================
# If LLM_PROVIDER=ollama, ensure Ollama is installed and model is pulled:
# ollama pull mistral:latest
# No API key needed for local Ollama
